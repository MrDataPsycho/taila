{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4165f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021b9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = Path(\"../.envs/dev.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06a2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings(BaseSettings):\n",
    "    OPENAI_API_KEY: str\n",
    "    HF_TOKEN: str\n",
    "    LLAMAPARSE_API_TOKEN: str\n",
    "\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=ENV_PATH if ENV_PATH.exists() else None,\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"ignore\",\n",
    "        case_sensitive=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0332665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5672f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=settings.OPENAI_API_KEY,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a77ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Conversation: Turn 1 ---\n",
      "Sending messages: [{'role': 'system', 'content': 'You are a helpful AI Tutor explaining Large Language Model concepts simply.'}, {'role': 'user', 'content': \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}]\n"
     ]
    }
   ],
   "source": [
    "# --- Block 2: First Turn - Asking the Initial Question ---\n",
    "print(\"\\n--- Starting Conversation: Turn 1 ---\")\n",
    "\n",
    "# Define the system message (persona) for the AI Tutor\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are a helpful AI Tutor explaining Large Language Model concepts simply.\"}\n",
    "\n",
    "# Define the user's first question\n",
    "user_message_1 = {\"role\": \"user\", \"content\": \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}\n",
    "\n",
    "# Create the messages list for the *first* API call\n",
    "messages_history = [\n",
    "    system_message,\n",
    "    user_message_1\n",
    "]\n",
    "\n",
    "print(f\"Sending messages: {messages_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf01557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for this call\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "TEMPERATURE = 0.5 # Slightly creative but still grounded explanation\n",
    "MAX_TOKENS = 150  # Limit the length of the explanation\n",
    "SEED = 123        # Make this explanation reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384f1962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making API call to gpt-4o-mini...\n",
      "API call successful.\n",
      "\n",
      "AI Tutor (Turn 1):\n",
      "Sure! In the context of Large Language Models (LLMs), a \"token\" is a basic unit of text that the model processes. Tokens can be words, parts of words, or even punctuation marks. \n",
      "\n",
      "Think of it this way: when you read a sentence, you break it down into smaller pieces to understand it better. Similarly, LLMs break down text into tokens to analyze and generate language.\n",
      "\n",
      "For example, the sentence \"I love apples!\" might be broken down into the following tokens:\n",
      "- \"I\"\n",
      "- \"love\"\n",
      "- \"apples\"\n",
      "- \"!\"\n",
      "\n",
      "In some cases, a token might represent just a part of a word, especially for longer or complex words. For instance, the word \"unhappiness\"\n",
      "\n",
      "Token Usage (Turn 1): Prompt=46, Completion=150, Total=196\n",
      "Finish Reason: length\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"\\nMaking API call to {MODEL}...\")\n",
    "    # Use the client object's method to create a chat completion\n",
    "    completion_1 = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_history,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        seed=SEED\n",
    "    )\n",
    "    print(\"API call successful.\")\n",
    "\n",
    "    # --- Process the response from the first turn ---\n",
    "    # Extract the assistant's reply content\n",
    "    assistant_response_1 = completion_1.choices[0].message.content\n",
    "    # Extract the full message object to add to history later\n",
    "    assistant_message_1 = completion_1.choices[0].message\n",
    "\n",
    "    print(\"\\nAI Tutor (Turn 1):\")\n",
    "    print(assistant_response_1)\n",
    "\n",
    "    # Print token usage for this call\n",
    "    usage_1 = completion_1.usage\n",
    "    print(f\"\\nToken Usage (Turn 1): Prompt={usage_1.prompt_tokens}, Completion={usage_1.completion_tokens}, Total={usage_1.total_tokens}\")\n",
    "    finish_reason_1 = completion_1.choices[0].finish_reason\n",
    "    print(f\"Finish Reason: {finish_reason_1}\")\n",
    "\n",
    "except openai.APIError as e:\n",
    "    # Handle API errors (e.g., server issues, rate limits)\n",
    "    print(f\"OpenAI API returned an API Error: {e}\")\n",
    "except openai.AuthenticationError as e:\n",
    "    # Handle Authentication errors (e.g., invalid API key)\n",
    "    print(f\"OpenAI Authentication Error: {e}\")\n",
    "except Exception as e:\n",
    "    # Handle other potential errors\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ab848ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Continuing Conversation: Turn 2 ---\n",
      "\n",
      "Sending updated messages: [{'role': 'system', 'content': 'You are a helpful AI Tutor explaining Large Language Model concepts simply.'}, {'role': 'user', 'content': \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}, ChatCompletionMessage(content='Sure! In the context of Large Language Models (LLMs), a \"token\" is a basic unit of text that the model processes. Tokens can be words, parts of words, or even punctuation marks. \\n\\nThink of it this way: when you read a sentence, you break it down into smaller pieces to understand it better. Similarly, LLMs break down text into tokens to analyze and generate language.\\n\\nFor example, the sentence \"I love apples!\" might be broken down into the following tokens:\\n- \"I\"\\n- \"love\"\\n- \"apples\"\\n- \"!\"\\n\\nIn some cases, a token might represent just a part of a word, especially for longer or complex words. For instance, the word \"unhappiness\"', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), {'role': 'user', 'content': \"Thanks! So, based on your explanation, are common words like 'the' or 'is' usually single tokens?\"}]\n"
     ]
    }
   ],
   "source": [
    "# --- Block 3: Second Turn - Asking a Follow-up Question ---\n",
    "print(\"\\n--- Continuing Conversation: Turn 2 ---\")\n",
    "\n",
    "# Assume the first turn was successful and we have 'assistant_message_1'\n",
    "# Define the user's second question, referencing the previous explanation\n",
    "user_message_2 = {\"role\": \"user\", \"content\": \"Thanks! So, based on your explanation, are common words like 'the' or 'is' usually single tokens?\"}\n",
    "\n",
    "# --- CRITICAL STEP: Update the message history ---\n",
    "# Append the assistant's *previous* response to the history\n",
    "messages_history.append(assistant_message_1)\n",
    "# Append the user's *new* question to the history\n",
    "messages_history.append(user_message_2)\n",
    "\n",
    "print(f\"\\nSending updated messages: {messages_history}\") # Notice how the list has grown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e02dfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the second call (could be the same or different)\n",
    "# Let's make it slightly more deterministic for a factual answer\n",
    "TEMPERATURE_2 = 0.2\n",
    "MAX_TOKENS_2 = 100\n",
    "# Using the same seed ensures the *entire conversation flow* is reproducible if inputs are identical\n",
    "SEED_2 = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96a0be2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making API call to gpt-4o-mini (Turn 2)...\n",
      "API call successful.\n",
      "\n",
      "AI Tutor (Turn 2):\n",
      "Yes, that's correct! Common words like \"the,\" \"is,\" \"and,\" and other short, frequently used words are typically represented as single tokens in most language models. These words are so common that they are often treated as standalone units.\n",
      "\n",
      "However, it's important to note that the way text is tokenized can vary depending on the specific model and its tokenization method. Some models might use different strategies that could break down words differently, but generally, common words tend to be single tokens.\n",
      "\n",
      "Token Usage (Turn 2): Prompt=228, Completion=99, Total=327\n",
      "Finish Reason: stop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"\\nMaking API call to {MODEL} (Turn 2)...\")\n",
    "    completion_2 = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_history, # Send the *full* history\n",
    "        temperature=TEMPERATURE_2,\n",
    "        max_tokens=MAX_TOKENS_2,\n",
    "        seed=SEED_2\n",
    "    )\n",
    "    print(\"API call successful.\")\n",
    "\n",
    "    # --- Process the response from the second turn ---\n",
    "    assistant_response_2 = completion_2.choices[0].message.content\n",
    "    # We don't strictly need to save assistant_message_2 unless continuing the conversation\n",
    "\n",
    "    print(\"\\nAI Tutor (Turn 2):\")\n",
    "    print(assistant_response_2)\n",
    "\n",
    "    # Print token usage for this call\n",
    "    usage_2 = completion_2.usage\n",
    "    print(f\"\\nToken Usage (Turn 2): Prompt={usage_2.prompt_tokens}, Completion={usage_2.completion_tokens}, Total={usage_2.total_tokens}\")\n",
    "    # Note: prompt_tokens for turn 2 will be larger as it includes the history from turn 1.\n",
    "    finish_reason_2 = completion_2.choices[0].finish_reason\n",
    "    print(f\"Finish Reason: {finish_reason_2}\")\n",
    "\n",
    "except openai.APIError as e:\n",
    "    print(f\"OpenAI API returned an API Error: {e}\")\n",
    "except openai.AuthenticationError as e:\n",
    "    print(f\"OpenAI Authentication Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef213508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "150\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# # Example usage object from completion_1 or completion_2:\n",
    "print(usage_1.prompt_tokens)  # -> number of input tokens\n",
    "print(usage_1.completion_tokens) # -> number of output tokens\n",
    "print(usage_1.total_tokens) # -> sum of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "219016a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Block 4: Cost Calculation Function & Example ---\n",
    "\n",
    "def calculate_cost(usage, input_price_per_mil, output_price_per_mil):\n",
    "    \"\"\"Calculates the cost of an API call based on token usage and prices.\n",
    "\n",
    "    Args:\n",
    "        usage: The usage object from the OpenAI completion response\n",
    "               (e.g., completion.usage). It should have attributes\n",
    "               'prompt_tokens' and 'completion_tokens'.\n",
    "        input_price_per_mil: Cost in USD per 1 million input tokens.\n",
    "        output_price_per_mil: Cost in USD per 1 million output tokens.\n",
    "\n",
    "    Returns:\n",
    "        The total cost in USD for the API call, or None if usage is invalid.\n",
    "    \"\"\"\n",
    "    if not usage or not hasattr(usage, 'prompt_tokens') or not hasattr(usage, 'completion_tokens'):\n",
    "        print(\"Warning: Invalid usage object provided for cost calculation.\")\n",
    "        return None\n",
    "\n",
    "    input_cost = (usage.prompt_tokens / 1_000_000) * input_price_per_mil\n",
    "    output_cost = (usage.completion_tokens / 1_000_000) * output_price_per_mil\n",
    "    total_cost = input_cost + output_cost\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83f7fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cost Calculations (GPT-4o-mini, April 2025 Rates) ---\n",
      "Prices: Input=$0.60/1M, Output=$2.40/1M\n"
     ]
    }
   ],
   "source": [
    "# --- Current Prices (April 2025) for GPT-4o-mini ---\n",
    "PRICE_INPUT_PER_MIL = 0.60\n",
    "PRICE_OUTPUT_PER_MIL = 2.40\n",
    "\n",
    "print(f\"\\n--- Cost Calculations (GPT-4o-mini, April 2025 Rates) ---\")\n",
    "print(f\"Prices: Input=${PRICE_INPUT_PER_MIL:.2f}/1M, Output=${PRICE_OUTPUT_PER_MIL:.2f}/1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "226be8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cost for Turn 1:\n",
      "  Prompt Tokens: 46, Completion Tokens: 150\n",
      "  Total Cost: $0.00038760\n",
      "\n",
      "Cost for Turn 2:\n",
      "  Prompt Tokens: 228, Completion Tokens: 99\n",
      "  Total Cost: $0.00037440\n",
      "\n",
      "Total Conversation Cost (Turn 1 + Turn 2): $0.00076200\n"
     ]
    }
   ],
   "source": [
    "# Calculate cost for Turn 1 (assuming completion_1 and usage_1 exist from Block 2)\n",
    "try:\n",
    "    if 'usage_1' in locals(): # Check if usage_1 variable exists\n",
    "         cost_1 = calculate_cost(usage_1, PRICE_INPUT_PER_MIL, PRICE_OUTPUT_PER_MIL)\n",
    "         if cost_1 is not None:\n",
    "              print(f\"\\nCost for Turn 1:\")\n",
    "              print(f\"  Prompt Tokens: {usage_1.prompt_tokens}, Completion Tokens: {usage_1.completion_tokens}\")\n",
    "              print(f\"  Total Cost: ${cost_1:.8f}\")\n",
    "    else:\n",
    "         print(\"\\nSkipping Turn 1 cost calculation (usage_1 not found).\")\n",
    "\n",
    "    # Calculate cost for Turn 2 (assuming completion_2 and usage_2 exist from Block 3)\n",
    "    if 'usage_2' in locals(): # Check if usage_2 variable exists\n",
    "        cost_2 = calculate_cost(usage_2, PRICE_INPUT_PER_MIL, PRICE_OUTPUT_PER_MIL)\n",
    "        if cost_2 is not None:\n",
    "            print(f\"\\nCost for Turn 2:\")\n",
    "            print(f\"  Prompt Tokens: {usage_2.prompt_tokens}, Completion Tokens: {usage_2.completion_tokens}\")\n",
    "            print(f\"  Total Cost: ${cost_2:.8f}\")\n",
    "    else:\n",
    "         print(\"\\nSkipping Turn 2 cost calculation (usage_2 not found).\")\n",
    "\n",
    "    # Calculate total conversation cost\n",
    "    if 'cost_1' in locals() and 'cost_2' in locals() and cost_1 is not None and cost_2 is not None:\n",
    "        total_conversation_cost = cost_1 + cost_2\n",
    "        print(f\"\\nTotal Conversation Cost (Turn 1 + Turn 2): ${total_conversation_cost:.8f}\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"\\nCould not calculate costs, a required variable is missing: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during cost calculation: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taila",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
