{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4165f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021b9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = Path(\"../.envs/dev.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06a2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings(BaseSettings):\n",
    "    OPENAI_API_KEY: str\n",
    "    HF_TOKEN: str\n",
    "    LLAMAPARSE_API_TOKEN: str\n",
    "\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=ENV_PATH if ENV_PATH.exists() else None,\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"ignore\",\n",
    "        case_sensitive=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0332665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5672f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=settings.OPENAI_API_KEY,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a77ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Conversation: Turn 1 ---\n",
      "Sending messages: [{'role': 'system', 'content': 'You are a helpful AI Tutor explaining Large Language Model concepts simply.'}, {'role': 'user', 'content': \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}]\n"
     ]
    }
   ],
   "source": [
    "# --- Block 2: First Turn - Asking the Initial Question ---\n",
    "print(\"\\n--- Starting Conversation: Turn 1 ---\")\n",
    "\n",
    "# Define the system message (persona) for the AI Tutor\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are a helpful AI Tutor explaining Large Language Model concepts simply.\"}\n",
    "\n",
    "# Define the user's first question\n",
    "user_message_1 = {\"role\": \"user\", \"content\": \"Can you explain what 'tokens' are in the context of LLMs, like I'm new to this?\"}\n",
    "\n",
    "# Create the messages list for the *first* API call\n",
    "messages_history = [\n",
    "    system_message,\n",
    "    user_message_1\n",
    "]\n",
    "\n",
    "print(f\"Sending messages: {messages_history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daf01557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for this call\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "TEMPERATURE = 0.5 # Slightly creative but still grounded explanation\n",
    "MAX_TOKENS = 150  # Limit the length of the explanation\n",
    "SEED = 123        # Make this explanation reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "384f1962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making API call to gpt-4o-mini...\n",
      "API call successful.\n",
      "\n",
      "AI Tutor (Turn 1):\n",
      "Sure! In the context of Large Language Models (LLMs), a \"token\" is a basic unit of text that the model processes. Tokens can be words, parts of words, or even punctuation marks. \n",
      "\n",
      "Think of it this way: when you read a sentence, you break it down into smaller pieces to understand it better. Similarly, LLMs break down text into tokens to analyze and generate language.\n",
      "\n",
      "For example, the sentence \"I love apples!\" might be broken down into the following tokens:\n",
      "- \"I\"\n",
      "- \"love\"\n",
      "- \"apples\"\n",
      "- \"!\"\n",
      "\n",
      "In some cases, a token might represent just a part of a word, especially for longer or complex words. For instance, the word \"unhappiness\"\n",
      "\n",
      "Token Usage (Turn 1): Prompt=46, Completion=150, Total=196\n",
      "Finish Reason: length\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"\\nMaking API call to {MODEL}...\")\n",
    "    # Use the client object's method to create a chat completion\n",
    "    completion_1 = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_history,\n",
    "        temperature=TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        seed=SEED\n",
    "    )\n",
    "    print(\"API call successful.\")\n",
    "\n",
    "    # --- Process the response from the first turn ---\n",
    "    # Extract the assistant's reply content\n",
    "    assistant_response_1 = completion_1.choices[0].message.content\n",
    "    # Extract the full message object to add to history later\n",
    "    assistant_message_1 = completion_1.choices[0].message\n",
    "\n",
    "    print(\"\\nAI Tutor (Turn 1):\")\n",
    "    print(assistant_response_1)\n",
    "\n",
    "    # Print token usage for this call\n",
    "    usage_1 = completion_1.usage\n",
    "    print(f\"\\nToken Usage (Turn 1): Prompt={usage_1.prompt_tokens}, Completion={usage_1.completion_tokens}, Total={usage_1.total_tokens}\")\n",
    "    finish_reason_1 = completion_1.choices[0].finish_reason\n",
    "    print(f\"Finish Reason: {finish_reason_1}\")\n",
    "\n",
    "except openai.APIError as e:\n",
    "    # Handle API errors (e.g., server issues, rate limits)\n",
    "    print(f\"OpenAI API returned an API Error: {e}\")\n",
    "except openai.AuthenticationError as e:\n",
    "    # Handle Authentication errors (e.g., invalid API key)\n",
    "    print(f\"OpenAI Authentication Error: {e}\")\n",
    "except Exception as e:\n",
    "    # Handle other potential errors\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e02dfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the second call (could be the same or different)\n",
    "# Let's make it slightly more deterministic for a factual answer\n",
    "TEMPERATURE_2 = 0.2\n",
    "MAX_TOKENS_2 = 100\n",
    "# Using the same seed ensures the *entire conversation flow* is reproducible if inputs are identical\n",
    "SEED_2 = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"\\nMaking API call to {MODEL} (Turn 2)...\")\n",
    "    completion_2 = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_history, # Send the *full* history\n",
    "        temperature=TEMPERATURE_2,\n",
    "        max_tokens=MAX_TOKENS_2,\n",
    "        seed=SEED_2\n",
    "    )\n",
    "    print(\"API call successful.\")\n",
    "\n",
    "    # --- Process the response from the second turn ---\n",
    "    assistant_response_2 = completion_2.choices[0].message.content\n",
    "    # We don't strictly need to save assistant_message_2 unless continuing the conversation\n",
    "\n",
    "    print(\"\\nAI Tutor (Turn 2):\")\n",
    "    print(assistant_response_2)\n",
    "\n",
    "    # Print token usage for this call\n",
    "    usage_2 = completion_2.usage\n",
    "    print(f\"\\nToken Usage (Turn 2): Prompt={usage_2.prompt_tokens}, Completion={usage_2.completion_tokens}, Total={usage_2.total_tokens}\")\n",
    "    # Note: prompt_tokens for turn 2 will be larger as it includes the history from turn 1.\n",
    "    finish_reason_2 = completion_2.choices[0].finish_reason\n",
    "    print(f\"Finish Reason: {finish_reason_2}\")\n",
    "\n",
    "except openai.APIError as e:\n",
    "    print(f\"OpenAI API returned an API Error: {e}\")\n",
    "except openai.AuthenticationError as e:\n",
    "    print(f\"OpenAI Authentication Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
